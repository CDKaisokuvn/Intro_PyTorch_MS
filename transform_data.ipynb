{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transform\r\n",
    "\r\n",
    "Data does not always come in its final processed from that is required for training machine learning algorithms. We use transforms to perform some manipulation of the data and make it suitable for training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All TorchVision datasets have two parameters(**transform** to modify the features and **target_transform** to modify the labels) that accept callables containing the transformation logic. The torchvision.transform module offers several commonly-used transforms out of the box"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## About the dataset\r\n",
    "\r\n",
    "The FashionMNIST features are in PIL image format and the labels are intergers. For training, we need the features as normalized and the labels as one-hot encoded tensors. To make these transformations, we use **ToTensor** and **Lambda**.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "from torchvision import datasets\r\n",
    "from  torchvision.transforms import ToTensor, Lambda\r\n",
    "\r\n",
    "ds = datasets.FashionMNIST(\r\n",
    "    root='data',\r\n",
    "    train=True,\r\n",
    "    download=True,\r\n",
    "    transform=ToTensor(),\r\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\duong\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ToTensor()\r\n",
    "\r\n",
    "ToTensor converts a PIL image or NumPy ndarray into a FloatTensor and scales the image's pixel intensity value in the range[0,1]\r\n",
    "\r\n",
    "## Lambda transforms\r\n",
    "\r\n",
    "Lambda transforms apply any user-defined lambda function. Here, we define a function to turn the interger in to a one-hot encoded tensor. It first creates a zero tensor of size 10( the number of labels in our dataset) and calls scatter which assigns a value=1 on the index as given by the label y."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def onehot_encode(y):\r\n",
    "     z = torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1)\r\n",
    "     print(z)\r\n",
    "\r\n",
    "onehot_encode(0)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "b8476f40adbb31d316263111a5645b453d35d3e96db58041b0655f021c3b1406"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}